{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing functions\n",
    "# get grayscale image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# noise removal\n",
    "def remove_noise(image):\n",
    "    return cv2.medianBlur(image,5)\n",
    " \n",
    "#thresholding\n",
    "def thresholding(image):\n",
    "    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "#dilation\n",
    "def dilate(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.dilate(image, kernel, iterations = 1)\n",
    "    \n",
    "#erosion\n",
    "def erode(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.erode(image, kernel, iterations = 1)\n",
    "\n",
    "#opening - erosion followed by dilation\n",
    "def opening(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "#canny edge detection\n",
    "def canny(image):\n",
    "    return cv2.Canny(image, 100, 200)\n",
    "\n",
    "#skew correction\n",
    "def deskew(image):\n",
    "    coords = np.column_stack(np.where(image > 0))\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated\n",
    "\n",
    "#template matching\n",
    "def match_template(image, template):\n",
    "    return cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED) \n",
    "\n",
    "#border removal\n",
    "def remove_border(image):\n",
    "    mask = np.zeros(image.shape, dtype=np.uint8)\n",
    "\n",
    "    cnts = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "    cv2.fillPoly(mask, cnts, [255,255,255])\n",
    "    mask = 255 - mask\n",
    "    result = cv2.bitwise_or(image, mask)\n",
    "    return result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inputting image as BGR\n",
    "# image = cv2.imread(\"D:/Download/ocr_test.png\")\n",
    "image = cv2.imread(\"E:/Internship/Common_resources/Screenshots/Screenshot 2023-12-15 141717.png\")\n",
    "# Converting to RGB\n",
    "rgbImage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# Preprocessing\n",
    "processed_img = get_grayscale(image)\n",
    "# processed_img = remove_noise(processed_img)\n",
    "# processed_img = dilate(processed_img)\n",
    "# processed_img = erode(processed_img)\n",
    "processed_img = thresholding(processed_img)\n",
    "processed_img = remove_border(processed_img)\n",
    "cv2.imshow('img', processed_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'level': [1, 2, 3, 4, 5, 2, 3, 4, 5], 'page_num': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'block_num': [0, 1, 1, 1, 1, 2, 2, 2, 2], 'par_num': [0, 0, 1, 1, 1, 0, 1, 1, 1], 'line_num': [0, 0, 0, 1, 1, 0, 0, 1, 1], 'word_num': [0, 0, 0, 0, 1, 0, 0, 0, 1], 'left': [0, 32, 32, 32, 32, 26, 26, 26, 26], 'top': [0, 9, 9, 9, 9, 41, 41, 41, 41], 'width': [96, 33, 33, 33, 33, 23, 23, 23, 23], 'height': [73, 25, 25, 25, 25, 25, 25, 25, 25], 'conf': [-1, -1, -1, -1, 53, -1, -1, -1, 93], 'text': ['', '', '', '', '19C', '', '', '', '50']}\n"
     ]
    }
   ],
   "source": [
    "# Custom script for pytesseract\n",
    "custom_config = r'--oem 3 --psm 12'\n",
    "pytesseract.pytesseract.tesseract_cmd = r'D:/Programs/Tesseract-OCR/tesseract.exe'\n",
    "\n",
    "# Extract data to array\n",
    "d = pytesseract.image_to_data(processed_img, config=custom_config, output_type=Output.DICT)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display bounding boxes\n",
    "n_boxes = len(d['level'])\n",
    "for i in range(n_boxes):\n",
    "    (l,t,w,h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
    "    # Draw bounding boxes on words only (conf > -1)\n",
    "    if int(d['conf'][i]) > -1:\n",
    "        cv2.rectangle(rgbImage, (l,t), (l+w, t+h), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow('img', rgbImage)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
